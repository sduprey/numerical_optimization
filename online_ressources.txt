https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/Index.html
https://computational-discovery-on-jupyter.github.io/Computational-Discovery-on-Jupyter/index.html
https://github.com/profConradi
https://github.com/inducer/numerics-notes/tree/main/demos/
https://www.ceremade.dauphine.fr/~bey/enseignement/Enseignement/All_enseignement_dauphine/Module_analyse_numerique/
https://www.ceremade.dauphine.fr/~bey/enseignement/Enseignement/All_enseignement_dauphine/Module_analyse_numerique/livre%20analyse%20num%c3%a9rique/



'Petit guide de calcul différentiel à l'usage de la license et de l'agrégation'
'Introduction à l'analyse numérique matricielle et à l'optimisation'
'Analyse numérique et équations différentielles'



Python & Neo4j
https://github.com/neo4j-graph-analytics/graph-algorithms-notebooks/tree/master/notebooks


Python & algos
https://www.bigocheatsheet.com/
https://notebook.community/pszjmb1/fun_with_SNA/NetworkX%20Tutorial
https://allendowney.github.io/DSIRP/
https://github.com/TirendazAcademy/PANDAS-TUTORIAL




https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/Index.html
http://www.cmap.polytechnique.fr/~beniamin.bogosel/OptimizationBachelor/
https://lemesurierb.people.cofc.edu/elementary-numerical-analysis-python/notebooks/newtons-method-python.html

1) Résolution d'équation
de la méthode du point fixe jusqu'à quasi Newton
https://indrag49.github.io/Numerical-Optimization/quasi-newton-methods.html
https://lemesurierb.people.cofc.edu/elementary-numerical-analysis-python/notebooks/newtons-method-python.html

2) Algèbre linéaire
Résolution directe et itérative de systèmes linéaires. Problèmes de valeurs propres.
Cas concret SVD&PCA
https://jonathan-hui.medium.com/machine-learning-singular-value-decomposition-svd-principal-component-analysis-pca-1d45e885e491
https://github.com/fastai/course22p2/blob/master/nbs/12_accel_sgd.ipynb

3) Optimization (descente de gradient)
https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb
https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch
https://www.kaggle.com/code/jhoward/why-you-should-use-a-framework

https://fa.bianp.net/teaching/2018/COMP-652/


4) ML techniques (random forest & gradient boosted trees)
https://xgboost.readthedocs.io/en/stable/tutorials/model.html
https://www.kaggle.com/code/jhoward/how-random-forests-really-work/
https://www.kaggle.com/code/prashant111/lightgbm-classifier-in-python

